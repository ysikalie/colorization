{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysikalie/colorization/blob/master/full_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M1YMgyCk2bZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate,Dense\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wT6vLAJq_odu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ]
    },
    {
      "metadata": {
        "id": "uTy5XaKvzbLx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2PsKYAiWJOt",
        "colab_type": "code",
        "outputId": "a2546a56-d386-4393-ab7c-849fb5c0d8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "cell_type": "code",
      "source": [
        "# Get images\n",
        "X = []\n",
        "for filename in os.listdir('Train/'):\n",
        "    X.append(img_to_array(load_img('Train/'+filename, target_size=(256, 256))))\n",
        "X = np.array(X, dtype=float)\n",
        "Xtrain = 1.0/255*X\n",
        "print(Xtrain.shape)\n",
        "X_Test = []\n",
        "for filename in os.listdir('Test/'):\n",
        "    X_Test.append(img_to_array(load_img('Test/'+filename,target_size=(256, 256))))\n",
        "X_Test = np.array(X_Test, dtype=float)\n",
        "Xtest = 1.0/255*X_Test\n",
        "print(Xtest.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-378a93b9d852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Train/'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_9nMVxisrOjD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "RwetnS_RiGOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# embed_input = Input(shape=(1000,))\n",
        "\n",
        "#Mid-Level features network\n",
        "gray_encoder_input = Input(shape=(128, 128, 1,))\n",
        "gray_encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(gray_encoder_input)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(gray_encoder_output)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(gray_encoder_output)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = BatchNormalization()(gray_encoder_output)\n",
        "\n",
        "#Add\n",
        "#Global Features network\n",
        "color_encoder_input = Input(shape=(128, 128, 3,))\n",
        "color_encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(color_encoder_input)\n",
        "color_encoder_output = BatchNormalization()(color_encoder_output)\n",
        "color_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(color_encoder_output)\n",
        "color_encoder_output = BatchNormalization()(color_encoder_output)\n",
        "color_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(color_encoder_output)\n",
        "color_encoder_output = BatchNormalization()(color_encoder_output)\n",
        "color_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(color_encoder_output)\n",
        "color_encoder_output = BatchNormalization()(color_encoder_output)\n",
        "color_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(color_encoder_output)\n",
        "color_encoder_output = BatchNormalization()(color_encoder_output)\n",
        "# color_encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(color_encoder_output)\n",
        "# color_encoder_input = BatchNormalization()(color_encoder_input)\n",
        "# color_encoder_output = Flatten(name='flatten')(color_encoder_output)\n",
        "# color_encoder_output = Dense(256, activation='sigmoid')(color_encoder_output)\n",
        "\n",
        "# #Fusion\n",
        "# fusion_output = RepeatVector(32 * 32)(color_encoder_output) \n",
        "# fusion_output = Reshape(([32, 32, 256]))(fusion_output)\n",
        "fusion_output = concatenate([gray_encoder_output, color_encoder_output], axis=3) \n",
        " \n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "\n",
        "model = Model(inputs=[gray_encoder_input, color_encoder_input], outputs=decoder_output)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HMjLg0UGWokx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "#Generate training data\n",
        "batch_size = 8\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "#         grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "#         embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "#         print([X_batch,lab_batch], Y_batch)\n",
        "        yield ([X_batch, lab_batch], Y_batch)\n",
        "\n",
        "\n",
        "def test_image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtest, batch_size=batch_size):\n",
        "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "#         embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(grayscaled_rgb)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield ([X_batch, lab_batch], Y_batch)\n",
        "               \n",
        "        \n",
        "#Train model \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "if os.path.exists('/home/weights-best.hdf5'):\n",
        "    model.load_weights('/home/weights-best.hdf5')\n",
        "    print(\"checkpoint_loaded\")\n",
        "model.compile(optimizer='rmsprop', loss='mse')\n",
        "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100, min_delta=1E-7, verbose=1)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "filepath=\"weights-best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max',period=1)\n",
        "model.fit_generator(image_a_b_gen(batch_size), epochs=2, \n",
        "                    steps_per_epoch=100,\n",
        "                    validation_data=test_image_a_b_gen(batch_size),\n",
        "                    validation_steps=105,\n",
        "                    callbacks=[checkpoint, rlrp, es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OCpGEa3_AkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "color_me = []\n",
        "for filename in os.listdir('/input/train/result31/'):\n",
        "    color_me.append(img_to_array(load_img('/input/train/result31/'+filename,target_size=(128, 128))))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "\n",
        "# Test model\n",
        "output = model.predict([color_me, gray_me])\n",
        "output = output * 128\n",
        "\n",
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((128, 128, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    imsave(\"/input/train/result10/img_\"+str(i)+\".png\", lab2rgb(cur))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}