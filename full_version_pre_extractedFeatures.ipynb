{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_version_pre-extractedFeatures.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysikalie/colorization/blob/master/full_version_pre_extractedFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LekLtug0uQS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import  VGG16,preprocess_input\n",
        "from keras.layers import Conv2D, UpSampling2D, Input, Reshape,  concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import  Model\n",
        "from keras.layers.core import RepeatVector\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from pickle import dump,load\n",
        "\n",
        "\n",
        "# Get images\n",
        "X = []\n",
        "for filename in os.listdir('Test/test140'):\n",
        "    X.append(img_to_array(load_img('Test/test140/'+filename, target_size=(256, 256))))\n",
        "X = np.array(X, dtype=float)\n",
        "Xtest = 1.0/255*X\n",
        "Xtest_length = len(Xtest)\n",
        "feature_file = 'test_features.pkl'\n",
        "batch_size = 2\n",
        "\n",
        "#Load weights\n",
        "inception = VGG16(weights='vgg16_weights_tf_dim_ordering_tf_kernels.h5', include_top=True)\n",
        "inception.graph = tf.get_default_graph()\n",
        "\n",
        "embed_input = Input(shape=(1000,))\n",
        "\n",
        "def extract_features(directory):\n",
        "    features = dict()\n",
        "    model = VGG16(weights='/home/zhaoyangze/PycharmProjects/ful_version/vgg16_weights_tf_dim_ordering_tf_kernels.h5', include_top=True)\n",
        "    model = Model(inputs=model.inputs, outputs=model.output)\n",
        "    for name in os.listdir(directory):\n",
        "        filename = directory + '/' + name\n",
        "        image = load_img(filename, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = image.reshape(1,image.shape[0], image.shape[1],image.shape[2])\n",
        "        image = preprocess_input(image)\n",
        "        feature = model.predict(image, verbose=0)\n",
        "        image_id = name.split('.')[0]\n",
        "        features[image_id] = feature\n",
        "    return features\n",
        "\n",
        "#Encoder\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input)\n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3)\n",
        "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output)\n",
        "fusion_output = BatchNormalization()(fusion_output)\n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = BatchNormalization()(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = BatchNormalization()(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = BatchNormalization()(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = BatchNormalization()(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = BatchNormalization()(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "def load_features(feature_file):\n",
        "    features = load(open('test_features.pkl', 'rb'))\n",
        "    features_value = features.values()\n",
        "    features_list = []\n",
        "    for feature in features_value:\n",
        "        features_list.append(feature)\n",
        "    feature_array = np.array(features_list)\n",
        "    print(feature_array.shape)\n",
        "    return feature_array\n",
        "\n",
        "\n",
        "def create_inception_embedding(batch_count,feature_file):\n",
        "    '''\n",
        "\n",
        "    :param batch_number:\n",
        "    :param feature_file:\n",
        "    :return: return the corresponding features of the current batch images\n",
        "    '''\n",
        "    feature_arrray = load_features(feature_file)\n",
        "    batch_number = batch_count*batch_size\n",
        "    batch_feature = feature_arrray[batch_number:batch_number+batch_size]\n",
        "    batch_feature = batch_feature.reshape(batch_size, 1000)\n",
        "    # print(batch_feature.shape)\n",
        "    return batch_feature\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "def train_image_a_b_gen(batch_size):\n",
        "    batch_count = 0\n",
        "    for batch in datagen.flow(Xtest, batch_size=batch_size):\n",
        "        batch_feature = create_inception_embedding(batch_count, feature_file)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:, :, :, 0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = 2*lab_batch[:, :, :, 1:] / 128 - 1\n",
        "        if batch_count==(Xtest_length/batch_size-1):\n",
        "            batch_count=0\n",
        "        else:\n",
        "            batch_count += 1\n",
        "        yield ([X_batch, batch_feature], Y_batch)\n",
        "\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "if os.path.exists('full_version_weights.hdf5'):\n",
        "    model.load_weights('full_version_weights.hdf5')\n",
        "    print(\"checkpoint_loaded\")\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50, min_delta=1E-7, verbose=20)\n",
        "filepath = \"full_version_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto',period=5)\n",
        "#Train model\n",
        "model.compile(optimizer='rmsprop', loss='mse')\n",
        "model.fit_generator(train_image_a_b_gen(batch_size), epochs=100, steps_per_epoch=70)\n",
        "model.save_weights(\"full_version_weights.hdf5\")\n",
        "\n",
        "\n",
        "\n",
        "color_me = []\n",
        "for filename in os.listdir('predict'):\n",
        "    color_me.append(img_to_array(load_img('predict/'+filename)))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
        "color_me_embed = create_inception_embedding(gray_me)\n",
        "color_me = rgb2lab(color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "\n",
        "# Test model\n",
        "output = model.predict([color_me, color_me_embed])\n",
        "output = (output +1)*64\n",
        "\n",
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eZ1Aa4L6utdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-P46r_BAuenf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}