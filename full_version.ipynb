{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysikalie/colorization/blob/master/full_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M1YMgyCk2bZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate,Dense\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTy5XaKvzbLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0344dbc2-020b-4054-9961-94d591d35db3"
      },
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 2.7.15rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OZO7H5AuWOB9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !tar  xvJf Train.tar.xz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2PsKYAiWJOt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get images\n",
        "X = []\n",
        "for filename in os.listdir('Train/'):\n",
        "    X.append(img_to_array(load_img('Train/'+filename)))\n",
        "X = np.array(X, dtype=float)\n",
        "Xtrain = 1.0/255*X\n",
        "\n",
        "#Addition\n",
        "X_test=[]\n",
        "for filename in os.listdir('Test/'):\n",
        "    X_test.append(img_to_array(load_img('Test/'+filename)))\n",
        "X_test = np.array(X_test, dtype=float)\n",
        "Xtest = 1.0/255*X_test\n",
        "\n",
        "#Load weights\n",
        "inception = InceptionResNetV2(weights='imagenet', include_top=True)\n",
        "inception.summary()\n",
        "\n",
        "inception.graph = tf.get_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0E1zvL2tjqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "img_path = '1.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "features = model.predict(x)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9nMVxisrOjD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "6c322_TvWlKy",
        "colab_type": "code",
        "outputId": "b2771a67-3e58-444f-97f5-615b809bffc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1277
        }
      },
      "cell_type": "code",
      "source": [
        "# embed_input = Input(shape=(1000,))\n",
        "\n",
        "#Mid-Level features network\n",
        "gray_encoder_input = Input(shape=(256, 256, 1,))\n",
        "gray_encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(gray_encoder_input)\n",
        "gray_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(gray_encoder_output)\n",
        "\n",
        "\n",
        "#Add\n",
        "#Global Features network\n",
        "color_encoder_input = Input(shape=(256, 256, 3,))\n",
        "color_encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(color_encoder_input)\n",
        "color_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(color_encoder_output)\n",
        "color_encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(color_encoder_output)\n",
        "color_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(color_encoder_output)\n",
        "color_encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(color_encoder_output)\n",
        "color_encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(color_encoder_output)\n",
        "color_encoder_output = Flatten(name='flatten')(color_encoder_output)\n",
        "color_encoder_output = Dense(1024, activation='sigmoid')(color_encoder_output)\n",
        "color_encoder_output = Dense(512, activation='sigmoid')(color_encoder_output)\n",
        "color_encoder_output = Dense(256, activation='sigmoid')(color_encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = RepeatVector(32 * 32)(color_encoder_output) \n",
        "fusion_output = Reshape(([32, 32, 256]))(fusion_output)\n",
        "fusion_output = concatenate([gray_encoder_output, fusion_output], axis=3) \n",
        " \n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[gray_encoder_input, color_encoder_input], outputs=decoder_output)\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_44 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 128, 128, 64) 1792        input_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 128, 128, 128 73856       conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "input_43 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 64, 64, 256)  295168      conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 128, 128, 64) 640         input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 128, 128, 128 73856       conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 32, 32, 512)  1180160     conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 64, 64, 128)  147584      conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 524288)       0           conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 64, 64, 256)  295168      conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 1024)         536871936   flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 32, 32, 256)  590080      conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 512)          524800      dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 32, 32, 512)  1180160     conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 256)          131328      dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 32, 32, 512)  2359808     conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_13 (RepeatVector) (None, 1024, 256)    0           dense_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 32, 32, 256)  1179904     conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 32, 32, 256)  0           repeat_vector_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_457[0][0]                 \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 32, 32, 128)  589952      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 64, 64, 64)   73792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 128, 128, 32) 18464       up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 128, 128, 16) 4624        conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 128, 128, 2)  290         conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 2)  0           conv2d_468[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 546,331,026\n",
            "Trainable params: 546,331,026\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HMjLg0UGWokx",
        "colab_type": "code",
        "outputId": "4987b693-7e30-4efc-c991-b54b6c2ba10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        }
      },
      "cell_type": "code",
      "source": [
        "def create_inception_embedding(grayscaled_rgb):\n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "        i = resize(i, (299, 299, 3), mode='constant')\n",
        "        grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    with inception.graph.as_default():\n",
        "        embed = inception.predict(grayscaled_rgb_resized)\n",
        "    return embed\n",
        "\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "#Generate training data\n",
        "batch_size = 1.\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "        embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        print([X_batch, embed], Y_batch)\n",
        "        yield ([X_batch, embed], Y_batch)\n",
        "\n",
        "#addition\n",
        "def testImage_a_b_gen(batch_size):\n",
        "    for batch in Xtest:\n",
        "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "        embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        print([X_batch, embed], Y_batch)\n",
        "        yield ([X_batch, embed], Y_batch)\n",
        "\n",
        "\n",
        "#Train model\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import RMSprop\n",
        "rmsprop = RMSprop(lr=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='mse')\n",
        "filepath = 'checkpoint'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n",
        "                            monitor='val_acc',\n",
        "                            verbose=1,\n",
        "                            save_best_only=True,\n",
        "                            mode='max')\n",
        "model.fit_generator(image_a_b_gen(batch_size), epochs=1, \n",
        "                    steps_per_epoch=1,callbacks=[checkpoint],\n",
        "                    validation_data=testImage_a_b_gen(batch_size),\n",
        "                    validation_steps=10\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c93326a1d99b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestImage_a_b_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                    )\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8OCpGEa3_AkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "！ nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}