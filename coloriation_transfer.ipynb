{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coloriation_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysikalie/colorization/blob/master/coloriation_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rKkW9xiLEAP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten,MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as  tf\n",
        "from keras.applications.densenet import DenseNet201\n",
        "X = []\n",
        "for filename in os.listdir('Train/'):\n",
        "    X.append(img_to_array(load_img('Train/'+filename, target_size=(224, 224))))\n",
        "X = np.array(X, dtype=float)\n",
        "Xtrain = 1.0/255*X\n",
        "X_Test = []\n",
        "for filename in os.listdir('Test/'):\n",
        "    X_Test.append(img_to_array(load_img('Test/'+filename,target_size=(224, 224))))\n",
        "X_Test = np.array(X_Test, dtype=float)\n",
        "\n",
        "Xtest = 1.0/255*X_Test\n",
        "\n",
        "#Load weights\n",
        "densenet = DenseNet201(weights='/home/zhaoyangze/PycharmProjects/ful_version/densenet201_weights_tf_dim_ordering_tf_kernels.h5' )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xTrCVfOEKleN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ensenet = Model(inputs=densenet.input, outputs=densenet.get_layer('pool2_conv').output)\n",
        "densenet.graph = tf.get_default_graph()\n",
        "densenet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L8XjiFZvKtTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#embed\n",
        "embed_input = Input(shape=(56, 56,128))\n",
        "\n",
        "#vgg block (56, 56 , 256)\n",
        "# Block 1\n",
        "gray_encoder_input = Input(shape=(224, 224, 1))\n",
        "gray_encoder_output = Conv2D(64, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block1_conv1')(gray_encoder_input)\n",
        "gray_encoder_output= Conv2D(64, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block1_conv2')(gray_encoder_output)\n",
        "gray_encoder_output = MaxPooling2D((2, 2), strides=(2, 2), \n",
        "                                   name='block1_pool')(gray_encoder_output)\n",
        "\n",
        "# Block 2\n",
        "gray_encoder_output = Conv2D(128, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block2_conv1')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(128, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block2_conv2')(gray_encoder_output)\n",
        "\n",
        "\n",
        "# Block 3\n",
        "gray_encoder_output= Conv2D(256, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block3_conv1')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block3_conv2')(gray_encoder_output)\n",
        "gray_encoder_output = Conv2D(256, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block3_conv3')(gray_encoder_output)\n",
        "gray_encoder_output= MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(gray_encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = concatenate([gray_encoder_output, embed_input], axis=3)\n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[gray_encoder_input,embed_input], outputs=decoder_output)\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9uMDKOdFwS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_inception_embedding(grayscaled_rgb):\n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "        i = resize(i, (224, 224, 3), mode='constant')\n",
        "        grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    with densenet.graph.as_default(): \n",
        "        embed = densenet.predict(grayscaled_rgb_resized)\n",
        "    return embed\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Generate training data\n",
        "batch_size = 1\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "#         grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "#         embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        embed = create_inception_embedding(lab_batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "#         print([X_batch,lab_batch], Y_batch)\n",
        "        yield ([X_batch, embed], Y_batch)\n",
        "\n",
        "\n",
        "def test_image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtest, batch_size=batch_size): \n",
        "        rgb_2grayscaled = rgb2gray(batch)\n",
        "        grayscaled_rgb = gray2rgb(rgb_2grayscaled)\n",
        "        lab_batch = rgb2lab(grayscaled_rgb)\n",
        "        embed = create_inception_embedding(lab_batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield ([X_batch, embed], Y_batch)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='mse')\n",
        "# model.summary()\n",
        "model.fit_generator(image_a_b_gen(batch_size), epochs=2,\n",
        "                    steps_per_epoch=1,\n",
        "                    validation_data=test_image_a_b_gen(batch_size),\n",
        "                    validation_steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}